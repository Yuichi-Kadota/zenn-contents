---
title: "Terraform入門"
emoji: "🐈"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["terraform","IaC"]
published: false
---

# Terraform入門

Terraformのオンボード目的に作成した記事です。

# IaC(Infrastructure as Code)

Terraformに入門する前に、IaCの定義や考え方についておさらいしましょう。

## そもそもIaCとは

IaCとは**インフラリソースのプロビジョニングをオートメーション**し、ソフトウェア開発のように行うアプローチです。

旧来オンプレミスでのインフラ構築は、ハードウェアの導入/敷設工事/結線作業など機械に任せる事が難しい作業も多いものでした。

しかし、仮想化技術の発達や近年のクラウドサービスの浸透に伴い、IaCツールによるオートメーションはインフラ構築と切っても切り離せないものとなりました。

多くのIaCツールは共通して以下の機能を持っています。

- 対象となるインフラリソースを特定の言語で定義する
- 記述されたコードからツールを介してインフラリソースの操作を行う

こうした機能を持つツールを通じて、インフラをコードとして管理する(オートメーション)のがIaCです。

## 代表的なツール群

IaCを実現するためのツールは数多くありますが、代表的なものを上げておきます。

重要なのは、「各IaCツールの対象範囲」を把握し用途に応じたものを選定する事です。

![iac.drawio.png](Terraform%E5%85%A5%E9%96%80%20ffacba80fcfa412dbc3060a1dea3b822/iac.drawio.png)

## メリット

- インフラリソースの設定がソースコード上で一覧として確認できる
- インフラ変更をGitの履歴から追うことができる
- CI/CDによる静的検査や、安全な自動適用などができる
- ソースコードの再利用により、環境複製などが正確かつ素早く行うことができる

## デメリット

- 小規模サービスであれば手作成してしまった方が早い
- 運用設計を行わないと、管理範囲が増えてしまいランニングコストも増える

# Terraformとは

---

[Terraform](https://www.terraform.io/)は、HashiCorp社が提供するIaCツールです。

（Terraform自体はGoで実装されたOSSツールとなっています）

本項ではその基本的な機能な仕組みについてご紹介します。

## 言語

HCL(HashiCorp Language)というJsonライクな独自のDSLを通じて、インフラリソースの管理を行う事ができます。

*HCLでの記述例*

```json
resource "aws_s3_bucket" "bucket" {
  bucket = "${local.bucket_name}-bucket"
  tags = {
    "Service" = "SaleSpot"
  }
}
```

## 対象

provider（[詳細は後述します](https://www.notion.so/Terraform-3e0e48890f5b4790bf6c3542742e95ed)）という機能により抽象化してパラメータを扱うため、数多くのプラットフォームやツールを対象とする事ができます。

*対応プラットフォーム例*

- クラウドプラットフォーム
    - AWS
    - GCP
    - Azure
- 監視系SaaSツール
    - Datadog
    - New Relic
- その他
    - Cloudflare
    - heroku
    - vercel

複数のプラットフォームを組み合わせて環境構築を行うような場合に、全てを同じ仕組みで管理できるというのがTerraformの大きなメリットの一つです。

## 基本①.providerとtfstate

具体的なterraformの仕組みを理解するために、`Provider`と`tfstate`の役割について解説します。

下記図の通り、terraformを実行する際には、実際の環境へのリソース作成とtfstateへの書き込みが行われます。

![provider.drawio (2).png](Terraform%E5%85%A5%E9%96%80%20ffacba80fcfa412dbc3060a1dea3b822/provider.drawio_(2).png)

### Provider

- 実行先のプラットフォームに合わせたパラメータを統合管理する役割を持ちます。（AWSであれば、AWS用のProviderをインストールして利用します。）
- 各プラットフォームのAPIパラメータ⇄HCLの橋渡しをする役割です。
    - HCLで指定されていないパラメータであっても、実行時にデフォルト値を設定する
    - 実行前にAPIパラメータのバリデーションを行う

### tfstate

- terraformを実行したリソースの情報が詰まったJsonファイルです。
- 実行時にTerraform+Providerを通して記録されます。
- 実行計画の取得時なども参照されます（※後述します）

## 基本②.実行サイクル（init/plan/apply）

次にterraformの実行サイクルについて理解しましょう。

terraformからリソースを構築するためには、以下のステップがあります。

![lifecycle.drawio.png](Terraform%E5%85%A5%E9%96%80%20ffacba80fcfa412dbc3060a1dea3b822/lifecycle.drawio.png)

### 1.init

`terraform init`コマンドで実行します

- Providerのインストール
- HCLの構文チェック
- Data Resource/Remote Stateなど外部データの読み込み

### 2.plan

`terraform plan`コマンドで実行します

- **tfstateと、HCLの差分比較**
    - 差分がある場合、実行計画の出力
- Providerベースのパラメータチェック

*plan結果例*

```json
Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_s3_bucket.bucket will be created
  + resource "aws_s3_bucket" "bucket" {
      + acceleration_status         = (known after apply)
      + acl                         = (known after apply)
      + arn                         = (known after apply)
      + bucket                      = "salespot-bucket"
      + bucket_domain_name          = (known after apply)
      + bucket_regional_domain_name = (known after apply)
      + force_destroy               = false
      + hosted_zone_id              = (known after apply)
      + id                          = (known after apply)
      + object_lock_enabled         = (known after apply)
      + policy                      = (known after apply)
      + region                      = (known after apply)
      + request_payer               = (known after apply)
      + tags                        = {
          + "Service" = "SaleSpot"
        }
      + tags_all                    = {
          + "CreatedBy" = "terraform"
          + "Env"       = "staging"
          + "Service"   = "SaleSpot"
        }
      + website_domain              = (known after apply)
      + website_endpoint            = (known after apply)

      + cors_rule {
          + allowed_headers = (known after apply)
          + allowed_methods = (known after apply)
          + allowed_origins = (known after apply)
          + expose_headers  = (known after apply)
          + max_age_seconds = (known after apply)
        }

      + grant {
          + id          = (known after apply)
          + permissions = (known after apply)
          + type        = (known after apply)
          + uri         = (known after apply)
        }

      + lifecycle_rule {
          + abort_incomplete_multipart_upload_days = (known after apply)
          + enabled                                = (known after apply)
          + id                                     = (known after apply)
          + prefix                                 = (known after apply)
          + tags                                   = (known after apply)

          + expiration {
              + date                         = (known after apply)
              + days                         = (known after apply)
              + expired_object_delete_marker = (known after apply)
            }

          + noncurrent_version_expiration {
              + days = (known after apply)
            }

          + noncurrent_version_transition {
              + days          = (known after apply)
              + storage_class = (known after apply)
            }

          + transition {
              + date          = (known after apply)
              + days          = (known after apply)
              + storage_class = (known after apply)
            }
        }

      + logging {
          + target_bucket = (known after apply)
          + target_prefix = (known after apply)
        }

      + object_lock_configuration {
          + object_lock_enabled = (known after apply)

          + rule {
              + default_retention {
                  + days  = (known after apply)
                  + mode  = (known after apply)
                  + years = (known after apply)
                }
            }
        }

      + replication_configuration {
          + role = (known after apply)

          + rules {
              + delete_marker_replication_status = (known after apply)
              + id                               = (known after apply)
              + prefix                           = (known after apply)
              + priority                         = (known after apply)
              + status                           = (known after apply)

              + destination {
                  + account_id         = (known after apply)
                  + bucket             = (known after apply)
                  + replica_kms_key_id = (known after apply)
                  + storage_class      = (known after apply)

                  + access_control_translation {
                      + owner = (known after apply)
                    }

                  + metrics {
                      + minutes = (known after apply)
                      + status  = (known after apply)
                    }

                  + replication_time {
                      + minutes = (known after apply)
                      + status  = (known after apply)
                    }
                }

              + filter {
                  + prefix = (known after apply)
                  + tags   = (known after apply)
                }

              + source_selection_criteria {
                  + sse_kms_encrypted_objects {
                      + enabled = (known after apply)
                    }
                }
            }
        }

      + server_side_encryption_configuration {
          + rule {
              + bucket_key_enabled = (known after apply)

              + apply_server_side_encryption_by_default {
                  + kms_master_key_id = (known after apply)
                  + sse_algorithm     = (known after apply)
                }
            }
        }

      + versioning {
          + enabled    = (known after apply)
          + mfa_delete = (known after apply)
        }

      + website {
          + error_document           = (known after apply)
          + index_document           = (known after apply)
          + redirect_all_requests_to = (known after apply)
          + routing_rules            = (known after apply)
        }
    }

Plan: 1 to add, 0 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
```

実行計画は、`add`,`change`,`destroy`の3つのアクションに分類されます。

HCLが書けたら実際に作成されるリソースやパラメータが意図したものと同じかどうか確認するために、必ず実行するようにしましょう

## 3.apply

`terraform apply`コマンドで実行します

[先ほどみた図](https://www.notion.so/Terraform-3e0e48890f5b4790bf6c3542742e95ed)の通りですが、以下が実行されます

- tfstateへの書き込み
- providerを通じてのリソース作成、変更（APIの発行）

リソース名の重複など、実際にAPIを発行しないとわからないようなエラーに関しては、apply時にエラーステータスとして返却される事があります。

## 基本③.ディレクトリ構成と実行単位

terraformの実行単位やディレクトリ構成について理解しましょう。

デファクトとなる構成はありませんが、今回は[test-infra](https://github.com/brainbuddy/brain_buddy_infra)リポジトリの設計を例にします。

### 構成例

```json
└── network
    └── stg                     ... ステージング環境ディレクトリ
        ├── backend.tf          ... tfstateの定義、providerの定義
        ├── vpc.tf

       ~~~

    └── prod  

			 ~~~
```

```json
<backend.tf>

provider "aws" {
  region = "ap-northeast-1"
  default_tags {
    tags = {
      CreatedBy = "terraform"
      Env       = "staging"
    }
  }
}

terraform {
  backend "s3" {
    bucket = "test-tfstate-staging"
    key    = "network/terraform.tfstate"
    region = "ap-northeast-1"
  }
}
```

```json
<vpc.tf>

resource "aws_vpc" "vpc" {
  cidr_block           = "10.1.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true
  tags = {
    Name = "${local.service}_${local.env}_vpc"
  }
}
```

- backend.tf
    - `provider`ブロックで、対象のプロバイダが`aws`である事を宣言します。
    - `terraform backnend`ブロックで、**tfstateの保存先を宣言します。**
        - 今回はAWS上の`test-tfstate-staging`というs3バケットにtfstateを保存しています。
        - バケット内のobject keyを`key`フィールドで宣言します
        - バケットのregionを`region`フィールドで宣言します
- vpc.tf
    - `resoure`ブロックで定義するリソースを宣言します。
        - 何を定義したらわからない場合は[公式Doc](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc)を参照しましょう
    - `resource`内のフィールドは、各リソースに対応したパラメータを記述します。
        - `local.~`と記述されている箇所は、変数参照している箇所です。（一旦読み飛ばしてもらってokです）

### 実行方法

`terraform`ブロックが宣言されているファイルのあるディレクトリが、実行時のディレクトリとなります。

（用語としてはワーキングディレクトリと呼びますが、あまり知られてないので忘れてもokです）

つまり、**今回の構成であれば、`./staging`ディレクトリが実行ディレクトリです。**

また、**実行時の単位=tfstateの単位**となります。

この例だと、`./staging` と `./production`は別のtfstateとして管理されます。

# まとめ

---

terraformの基本的な仕組みを解説しました。

特にprovider,tfstateなどの機能はある程度理解していないと思わぬ事故に繋がるため、よく理解を深める事が大切です。

また実際に開発を行う上ではterraformの知識だけではなく対象のプラットフォームの知識（AWS、GCP…etc）も不可欠です。

最後に、terraform(×AWS)で参考になる書籍を紹介します。

****[実践Terraform　AWSにおけるシステム設計とベストプラクティス](https://nextpublishing.jp/book/10983.html)****

また、terraformのインストール等、セットアップ方法については[test-infraのREADME](https://github.com/brainbuddy/brain_buddy_infra#readme)に記載しているのでそちらをご参照ください。